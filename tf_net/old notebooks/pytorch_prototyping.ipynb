{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "snpnet",
   "display_name": "snpnet",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_to_tensor(seq):    \n",
    "    seq = list(seq[0])\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(['A', 'T', 'C', 'G'])\n",
    "    test = le.transform(seq)\n",
    "    targets = torch.as_tensor(test,dtype=int)\n",
    "    targets = F.one_hot(targets, num_classes=4)\n",
    "    return targets.reshape(1,40,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pos_set = pd.read_csv(\"data/ATF2.fa\",header=None).iloc[1::2]\n",
    "pos_set = pos_set[pos_set[0].str.contains(\"N\")==False]\n",
    "neg_set = pd.read_csv(\"data/ATF2_neg.fa\",header=None).iloc[1::2]\n",
    "neg_set = neg_set[neg_set[0].str.contains(\"N\")==False]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_set[\"seq\"] = pos_set.apply(lambda x: seq_to_tensor(x), axis=1)\n",
    "neg_set[\"seq\"] = neg_set.apply(lambda x: seq_to_tensor(x), axis=1)\n",
    "pos_set[\"label\"] = torch.as_tensor(1)\n",
    "neg_set[\"label\"] = torch.as_tensor(0)\n",
    "data = pos_set.append(neg_set)\n",
    "data.drop(columns=[0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                      seq      label\n",
       "57737   [[[tensor(0), tensor(0), tensor(1), tensor(0)]...  tensor(1)\n",
       "491087  [[[tensor(0), tensor(0), tensor(0), tensor(1)]...  tensor(1)\n",
       "513579  [[[tensor(0), tensor(0), tensor(0), tensor(1)]...  tensor(1)\n",
       "115745  [[[tensor(1), tensor(0), tensor(0), tensor(0)]...  tensor(1)\n",
       "40975   [[[tensor(1), tensor(0), tensor(0), tensor(0)]...  tensor(1)\n",
       "...                                                   ...        ...\n",
       "61393   [[[tensor(0), tensor(0), tensor(0), tensor(1)]...  tensor(0)\n",
       "358767  [[[tensor(0), tensor(0), tensor(0), tensor(1)]...  tensor(1)\n",
       "311909  [[[tensor(0), tensor(1), tensor(0), tensor(0)]...  tensor(0)\n",
       "221915  [[[tensor(0), tensor(0), tensor(0), tensor(1)]...  tensor(1)\n",
       "300433  [[[tensor(0), tensor(0), tensor(0), tensor(1)]...  tensor(1)\n",
       "\n",
       "[415233 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>seq</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>57737</th>\n      <td>[[[tensor(0), tensor(0), tensor(1), tensor(0)]...</td>\n      <td>tensor(1)</td>\n    </tr>\n    <tr>\n      <th>491087</th>\n      <td>[[[tensor(0), tensor(0), tensor(0), tensor(1)]...</td>\n      <td>tensor(1)</td>\n    </tr>\n    <tr>\n      <th>513579</th>\n      <td>[[[tensor(0), tensor(0), tensor(0), tensor(1)]...</td>\n      <td>tensor(1)</td>\n    </tr>\n    <tr>\n      <th>115745</th>\n      <td>[[[tensor(1), tensor(0), tensor(0), tensor(0)]...</td>\n      <td>tensor(1)</td>\n    </tr>\n    <tr>\n      <th>40975</th>\n      <td>[[[tensor(1), tensor(0), tensor(0), tensor(0)]...</td>\n      <td>tensor(1)</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>61393</th>\n      <td>[[[tensor(0), tensor(0), tensor(0), tensor(1)]...</td>\n      <td>tensor(0)</td>\n    </tr>\n    <tr>\n      <th>358767</th>\n      <td>[[[tensor(0), tensor(0), tensor(0), tensor(1)]...</td>\n      <td>tensor(1)</td>\n    </tr>\n    <tr>\n      <th>311909</th>\n      <td>[[[tensor(0), tensor(1), tensor(0), tensor(0)]...</td>\n      <td>tensor(0)</td>\n    </tr>\n    <tr>\n      <th>221915</th>\n      <td>[[[tensor(0), tensor(0), tensor(0), tensor(1)]...</td>\n      <td>tensor(1)</td>\n    </tr>\n    <tr>\n      <th>300433</th>\n      <td>[[[tensor(0), tensor(0), tensor(0), tensor(1)]...</td>\n      <td>tensor(1)</td>\n    </tr>\n  </tbody>\n</table>\n<p>415233 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data = data.sample(frac=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        sample = {'seq': self.data.iloc[idx][\"seq\"], 'label': self.data.iloc[idx][\"label\"]}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "trainset = SeqDataset(data.iloc[:int(len(data)*0.8)])\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = SeqDataset(data.iloc[int(len(data)*0.8):])\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for i, data in enumerate(trainloader, 0):\n",
    "#     input_key,label_key = data\n",
    "#     inputs = data[input_key]\n",
    "#     labels = data[label_key]\n",
    "#     print(inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(4, 4), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=1, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 64, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=592, out_features=320, bias=True)\n",
       "  (fc2): Linear(in_features=320, out_features=160, bias=True)\n",
       "  (fc3): Linear(in_features=160, out_features=80, bias=True)\n",
       "  (fc4): Linear(in_features=80, out_features=2, bias=True)\n",
       "  (soft): Softmax(dim=None)\n",
       ")"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1,out_channels=16, kernel_size=4,stride=1,padding=0)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16,out_channels=64, kernel_size=2,stride=1,padding=0)\n",
    "        self.fc1 = nn.Linear(592, 320)\n",
    "        self.fc2 = nn.Linear(320, 160)\n",
    "        self.fc3 = nn.Linear(160, 80)\n",
    "        self.fc4 = nn.Linear(80, 2)\n",
    "        self.soft = nn.Softmax()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x.float()))\n",
    "        #x = F.relu(self.conv2(x))\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        x = self.fc4(x)\n",
    "        #x = self.soft(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1,  2000] loss: 0.665\n",
      "[1,  4000] loss: 0.663\n",
      "[1,  6000] loss: 0.665\n",
      "[1,  8000] loss: 0.661\n",
      "[1, 10000] loss: 0.656\n",
      "[2,  2000] loss: 0.599\n",
      "[2,  4000] loss: 0.551\n",
      "[2,  6000] loss: 0.536\n",
      "[2,  8000] loss: 0.531\n",
      "[2, 10000] loss: 0.520\n",
      "[3,  2000] loss: 0.517\n",
      "[3,  4000] loss: 0.515\n",
      "[3,  6000] loss: 0.514\n",
      "[3,  8000] loss: 0.513\n",
      "[3, 10000] loss: 0.510\n",
      "[4,  2000] loss: 0.507\n",
      "[4,  4000] loss: 0.506\n",
      "[4,  6000] loss: 0.505\n",
      "[4,  8000] loss: 0.504\n",
      "[4, 10000] loss: 0.502\n",
      "[5,  2000] loss: 0.499\n",
      "[5,  4000] loss: 0.499\n",
      "[5,  6000] loss: 0.498\n",
      "[5,  8000] loss: 0.497\n",
      "[5, 10000] loss: 0.497\n",
      "[6,  2000] loss: 0.492\n",
      "[6,  4000] loss: 0.490\n",
      "[6,  6000] loss: 0.490\n",
      "[6,  8000] loss: 0.494\n",
      "[6, 10000] loss: 0.491\n",
      "[7,  2000] loss: 0.483\n",
      "[7,  4000] loss: 0.487\n",
      "[7,  6000] loss: 0.483\n",
      "[7,  8000] loss: 0.484\n",
      "[7, 10000] loss: 0.485\n",
      "[8,  2000] loss: 0.476\n",
      "[8,  4000] loss: 0.477\n",
      "[8,  6000] loss: 0.477\n",
      "[8,  8000] loss: 0.478\n",
      "[8, 10000] loss: 0.481\n",
      "[9,  2000] loss: 0.465\n",
      "[9,  4000] loss: 0.469\n",
      "[9,  6000] loss: 0.472\n",
      "[9,  8000] loss: 0.475\n",
      "[9, 10000] loss: 0.474\n",
      "[10,  2000] loss: 0.461\n",
      "[10,  4000] loss: 0.461\n",
      "[10,  6000] loss: 0.466\n",
      "[10,  8000] loss: 0.466\n",
      "[10, 10000] loss: 0.469\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        input_key,label_key = data\n",
    "        inputs = data[input_key]\n",
    "        labels = data[label_key]\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './atf2.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "input_key,label_key = dataiter.next()\n",
    "inputs = data[input_key]\n",
    "labels = data[label_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([ 1.2419e+00,  4.8082e-01,  3.1543e-01,  1.1310e-01,  1.0642e+00,\n         7.3113e-01, -1.3869e-02,  1.4972e+00,  1.7799e-01,  3.3801e+00,\n         8.0673e-02,  9.7669e-01,  2.7443e-01, -5.1136e-03,  2.7757e-01,\n         4.0011e-01,  8.5468e-01,  8.1810e-01,  1.1333e+00,  1.5063e-01,\n         2.3719e-01,  3.0003e-01, -2.9465e-03,  3.2222e+00,  8.0507e-01,\n         5.9400e-01], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "outputs = net(inputs)\n",
    "\n",
    "test, predicted = torch.max(outputs, 1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n        0, 0]) tensor([1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n        0, 0])\n"
     ]
    }
   ],
   "source": [
    "print(predicted,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy of the network on the 10000 test images: 74 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        input_key,label_key = data\n",
    "        inputs = data[input_key]\n",
    "        labels = data[label_key]\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(inputs)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy for class 0.000000 is: 63.5 %\nAccuracy for class 1.000000 is: 80.9 %\n"
     ]
    }
   ],
   "source": [
    "# prepare to count predictions for each class\n",
    "classes = [0,1]\n",
    "correct_pred = {classname: 0 for classname in classes}\n",
    "total_pred = {classname: 0 for classname in classes}\n",
    "\n",
    "# again no gradients needed\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        input_key,label_key = data\n",
    "        inputs = data[input_key]\n",
    "        labels = data[label_key]\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        # collect the correct predictions for each class\n",
    "        for label, prediction in zip(labels, predictions):\n",
    "            if label == prediction:\n",
    "                correct_pred[classes[label]] += 1\n",
    "            total_pred[classes[label]] += 1\n",
    "\n",
    "\n",
    "# print accuracy for each class\n",
    "for classname, correct_count in correct_pred.items():\n",
    "    accuracy = 100 * float(correct_count) / total_pred[classname]\n",
    "    print(\"Accuracy for class {:5f} is: {:.1f} %\".format(classname,\n",
    "                                                   accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}